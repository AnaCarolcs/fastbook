{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Do you need these for deep learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) Lots of math - False \n",
    "\n",
    "(b) Lots of data - False\n",
    "\n",
    "(c) Lots of expensive computers - False\n",
    "\n",
    "(d) A PhD - False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) Muita matemática - Falso\n",
    "\n",
    "(b) Muitos dados - Falso\n",
    "\n",
    "(c) Muita experiência com computadores - Falso\n",
    "\n",
    "(d) Doutorado - Falso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Name five areas where deep learning is now the best in the world:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any five of the following:\n",
    "\n",
    "- Natural Language Processing (NLP) – Question Answering, Document Summarization and Classification, etc.\n",
    "- Computer Vision – Satellite and drone imagery interpretation, face detection and recognition, image captioning, etc.\n",
    "- Medicine – Finding anomalies in medical images (ex: CT, X-ray, MRI), detecting features in tissue slides (pathology), diagnosing diabetic retinopathy, etc.\n",
    "- Biology – Folding proteins, classifying, genomics tasks, cell classification, etc.\n",
    "- Image generation/enhancement – colorizing images, improving image resolution (super-resolution), removing noise from images (denoising), converting images to art in style of famous artists (style transfer), etc.\n",
    "- Recommendation systems – web search, product recommendations, etc.\n",
    "- Playing games – Super-human performance in Chess, Go, Atari games, etc\n",
    "- Robotics – handling objects that are challenging to locate (e.g. transparent, shiny, lack of texture) or hard to pick up\n",
    "- Other applications – financial and logistical forecasting; text to speech; much much more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. What was the name of the first device that was based on the principle of the artificial neuron?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Mark I perceptron\" built by Frank Rosenblatt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Based on the book of the same name, what are the requirements for “Parallel Distributed Processing”?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A set of <i>processing units</i>\n",
    "- A state of <i>activation</i>\n",
    "- An <i>output function</i> for each unit\n",
    "- A <i>pattern of connectivity</i> among units\n",
    "- A <i>propagation rule</i> for propagating patterns of activities through the network of connectivities\n",
    "- An <i>activation rule</i> for combining the inputs impinging on a unit with the current state of that unit to produce a new level of activation for the unit\n",
    "- A <i>learning rule</i> whereby patterns of connectivity are modified by experience\n",
    "- An <i>environment</i> within which the system must operate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. What were the two theoretical misunderstandings that held back the field of neural networks?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In 1969, Marvin Minsky and Seymour Papert demonstrated in their book, “Perceptrons”, that a single layer of artificial neurons cannot learn simple, critical mathematical functions like XOR logic gate. While they subsequently demonstrated in the same book that additional layers can solve this problem, only the first insight was recognized, leading to the start of the first AI winter.\n",
    "\n",
    "In the 1980’s, models with two layers were being explored. Theoretically, it is possible to approximate any mathematical function using two layers of artificial neurons. However, in practices, these networks were too big and too slow. While it was demonstrated that adding additional layers improved performance, this insight was not acknowledged, and the second AI winter began. In this past decade, with increased data availability, and improvements in computer hardware (both in CPU performance but more importantly in GPU performance), neural networks are finally living up to its potential."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em 1969, Marvin Minsky e Seymour Papert demonstraram em seu livro, \"Perceptrons\", que uma única camada de neurônios artificiais não pode aprender funções simples, críticas e matemáticas como portas lógicas XOR. Enquanto em seguida eles demonstram no mesmo livro que adicionar camadas pode resolver o problema, apenas o primeiro insight foi reconhecido, iniciando o primeiro AI winter.\n",
    "\n",
    "Em 1980, modelos com duas camadas foram sendo em exploradas. Teoricamente, é possível aproximar qualquer função matemática usando duas camadas de neurônios artificiais. Em todo caso, na prática, essas conexões eram muito grandes e muito lentas. Enquanto foi demonstrado que adicionando camadas adicionais melhorou a performance, o insight não foi reconhecida e a segunda AI winter começou. Na década passada, com maior disponibilidade de dados, e melhora dos hardwares (tanto em performance de CPU, mas, mais importante, em performance de GPU), conexões neurais estão finalmente vivendo de acordo com seu potencial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. What is a GPU?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
